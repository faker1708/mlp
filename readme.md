

做最简单的事

封装一个可复用的mlp




mlp，
输入，神经网络结构 。

方法
建立神经网络 
前向
计算损失
更新



不行，我还是想自己手写，它们的封装好蠢啊。我就给个列表，生成网络不行吗？妈的什么都要手写。


刚刚两个问题
1   最后一层，确实不能加relu，否则经常搞得梯度为0，无法更新了。
2   lr太大可以会发散，0.03也可能会发散，要注意。


现在的问题，要把类封装一下。
添加些功能。




测试这些功能
1   1条数据，通过
2   多条数据
3   多层网络

自动变更 学习率 精度  监测收敛还是发散。

有时候网络复杂 化，反而损失降不下去。
修改网络结构 ，有助于增大训练 精度 （但至于测试精度 则不是神经网络的义务了）

我去，简单的网络，复杂的数据，精度 可以非常高。
复杂 的网络，简单的数据，精度 并不能高。



总结
不要在python内置对象上面添加方法和属性。因为这种行为是不可预期的，最好的做法继承内置对象，在派生子类中添加属性，方法等。



唉？层数增加后，反而表现好了。

